{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d905be6-6ba6-4b1f-8c87-46593bf4961a",
   "metadata": {},
   "source": [
    "Los autoencoders son una herramienta muy poderosa que está pensada para hacer representaciones eficientes de los datos, la máquina va a aprender a representar los datos de manera eficiente.\n",
    "\n",
    "Un autoencoder básicamente lo que hace es intentar aprender una función que comprime los datos que recibe reduciéndolos a una representación codificada de dimensión mucho menor y luego los reconstruye a su forma original o a una aproximación cercana.\n",
    "\n",
    "Para poder usar los autoencoders tenemos que descargar la librería de Tensorflow, ya que no viene con Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21056a73-967e-4c6e-8568-d5167dc64016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp313-cp313-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cesargael.garcia\\appdata\\local\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 8.4/332.0 MB 42.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 17.0/332.0 MB 42.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 26.0/332.0 MB 43.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 33.6/332.0 MB 40.8 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 40.6/332.0 MB 39.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 44.8/332.0 MB 36.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 50.6/332.0 MB 35.6 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 55.1/332.0 MB 34.0 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 59.8/332.0 MB 32.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 64.5/332.0 MB 31.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 69.5/332.0 MB 30.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 75.0/332.0 MB 29.9 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 80.0/332.0 MB 29.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 86.2/332.0 MB 29.5 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 92.3/332.0 MB 29.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 99.1/332.0 MB 29.5 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 106.2/332.0 MB 29.6 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 113.2/332.0 MB 29.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 120.8/332.0 MB 30.1 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 129.0/332.0 MB 30.4 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 135.0/332.0 MB 30.4 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 140.0/332.0 MB 30.1 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 145.0/332.0 MB 29.8 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 149.9/332.0 MB 29.5 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 156.5/332.0 MB 29.6 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 162.5/332.0 MB 29.6 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 169.6/332.0 MB 29.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 176.7/332.0 MB 29.9 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 184.3/332.0 MB 30.1 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 192.2/332.0 MB 30.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 199.2/332.0 MB 30.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 207.9/332.0 MB 30.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 215.7/332.0 MB 31.0 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 219.4/332.0 MB 30.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 224.1/332.0 MB 30.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 227.5/332.0 MB 30.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 231.2/332.0 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 235.4/332.0 MB 29.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 239.1/332.0 MB 29.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 243.5/332.0 MB 29.0 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 248.0/332.0 MB 28.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 253.0/332.0 MB 28.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 258.2/332.0 MB 28.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 263.5/332.0 MB 28.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 269.2/332.0 MB 28.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 275.0/332.0 MB 28.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 281.3/332.0 MB 27.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 287.6/332.0 MB 27.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 293.9/332.0 MB 27.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 300.9/332.0 MB 27.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 308.3/332.0 MB 28.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 315.9/332.0 MB 28.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 323.5/332.0 MB 28.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.4/332.0 MB 29.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 29.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 29.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 332.0/332.0 MB 27.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.7/4.7 MB 32.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl (212 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 32.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 29.5 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 8.9/26.4 MB 42.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.4 MB 42.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 43.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 38.9 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp313-cp313-win_amd64.whl (314 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   -- -------------------------------------  1/16 [libclang]\n",
      "   ----- ----------------------------------  2/16 [flatbuffers]\n",
      "   ------------ ---------------------------  5/16 [optree]\n",
      "   --------------- ------------------------  6/16 [opt_einsum]\n",
      "   --------------- ------------------------  6/16 [opt_einsum]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   -------------------- -------------------  8/16 [grpcio]\n",
      "   ---------------------- -----------------  9/16 [google_pasta]\n",
      "   ------------------------- -------------- 10/16 [gast]\n",
      "   ------------------------------ --------- 12/16 [absl-py]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   -------------------------------- ------- 13/16 [tensorboard]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ----------------------------------- ---- 14/16 [keras]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ------------------------------------- -- 15/16 [tensorflow]\n",
      "   ---------------------------------------- 16/16 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 keras-3.12.0 libclang-18.1.1 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0442b0f-4a1e-4507-8be2-fa2e66d70efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1fca6b-167f-4a6a-ac1f-3ecf909e110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c39d28-1097-4b59-a71a-ee9820de109e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 1797\\n:Number of Attributes: 64\\n:Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n:Missing Attribute Values: None\\n:Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n:Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. dropdown:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos = load_digits()\n",
    "digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04002ca9-de21-4fec-8471-b302008ed314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69295112-d154-4112-8efa-635b0ed5d8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos['data'][0].reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2955aed-a167-4bf7-bf91-a1ad1cb78c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digitos['data'][0].reshape(8, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90252448-2821-4a98-aae2-aaee8d8c6ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digitos['images'][0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3239425-a043-487c-bd06-ed0e38bcf419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digitos['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd751686-d9a1-4a80-a973-3b7e5ba2a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar valores\n",
    "X = X / 16.0 # se divide entre 16 porque los numeros de digitos tipicamente\n",
    "             # tienen valores en el rango de 0 - 16, asi que dividiendo sus valores\n",
    "             # entre 16.0 nos aseguramos que el resultado este entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b3678c-d134-4239-b0b8-c395d64fb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entrena, X_prueba = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2ab377-b283-466a-8829-94f70264555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen_entrada = Input(shape=(64, )) # es la forma especifica que el modelo va a esperar que tengamos nuestros datos\n",
    "                                     # o sea que el arreglo de 8x8 va a pasar de forma aplanada siendo un arreglo de una diemension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb58e73a-bb66-453c-a96b-7c3864f734da",
   "metadata": {},
   "source": [
    "Después tenemos que hacer la codificación y su decodificación, para eso usaremos la función **dense** que se refiere a una capa densa que tendrá muchísimos puntos de información y que todos esos puntos van a estar conectados entre sí como una red de neuronas donde cada neurona tiene una conexión directa con cada una de las demás neuronas.\n",
    "\n",
    "A la función 'dense' se le tiene que definir el **número de neuronas** que tiene la capa densa, la cantidad de neuronas dependerá de muchos factores, de objetos específicos del modelo o del conjunto de datos con el que estés trabajando.\n",
    "\n",
    "Esta decisión sobre el número de neuronas puede influir en la **capacidad del modelo para aprender patrones complejos de los datos**, SI tienes un **número grande de neuronas** puede aumentar la capacidad del modelo para aprender detalles finos de los datos de entrenamiento (que sería beneficioso si tu conjunto de datos es muy complejo o muy variado), pero también puede pasar que el modelo aprenda tanto que aprende incluso lo que se le llama **ruido** en los datos de entrenamiento, en lugar de relaciones importantes generales y esto puedes perjudicar su rendimiento en datos nuevos y, por otro lado, si eliges un **número pequeño de neuronas** el modelo podría no tener tanta capacidad para aprender adecuadamente esos patrones de los datos, lo que como resultado crear un modelo demasiado simple que es incapaz de capturar la estructura subyacente de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f9ba453-0c84-4e3f-b526-9d576de2ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "codificado = Dense(32, activation='relu')(imagen_entrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe03262-9037-4164-b0ec-5500d667b713",
   "metadata": {},
   "source": [
    "32 es el número de neuronas y en este caso es un punto de inicio ilustrativo, ya que no es un estándar, solo se seleccionó porque es la mitad de los 64 píxeles que tiene la imagen. El argumento `activation` que está como \"relu\" se refiere **rectified linear unit** que es una de las funciones de activación más comunes en las redes neuronales por su simplicidad y su eficacia. Después por separado tenemos `imagen_entrada` que básicamente es el path para decirle a 'dense' que a la capa densa que hemos definido debe aplicarse a las entradas que proporcionaremos por imagen entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8457c-1edf-421e-be5a-010b8b21bc15",
   "metadata": {},
   "source": [
    "En términos simples, una capa densa es un grupo de neuronas trabajando juntas donde cada una contribuye un poco basada en su propio peso para transformar un nuevo mensaje que es la salida de la capa que combina todos sus puntos de vista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4da81eaa-9c69-4fca-960a-882fa1c73404",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodificado = Dense(64, activation='sigmoid')(codificado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48692344-4c81-4a1e-af6c-81a47b350579",
   "metadata": {},
   "source": [
    "Para decodificar los datos de salida de la capa densa tenemos que darle la cantidad de entradas original **64**, `activation` lo marcamos como \"sigmoid\" que es una función que convierte los valores de entrada a la capa en valores entre 0 y 1, lo cual es muy útil, ya que los valores de entrada originales también estaban entre 0 y 1, por último le decimos que la capa dense se aplica a la salida de la capa de codificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "531018f9-09c0-4adc-9798-e58b052d087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(imagen_entrada, decodificado) # preparacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb6205b6-ed67-4a38-bc8c-718da1b6242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03b2985-9c4e-4dac-857c-874d9a3f8e41",
   "metadata": {},
   "source": [
    "El optimizador es un algoritmo que ajusta los pesos del modelo, `adam` es uno de los optimizadores más populares y más efectivos porque ajusta la tasa de aprendizaje automáticamente y funciona en la mayoría de los casos sin más configuración.\n",
    "\n",
    "La función de perdida mide que tan bien el modelo está haciendo su trabajo, es este caso es reconstruir la imagen original a partir de la versión comprimida, `binary_crossentropy` es una elección muy común cuando los datos de entrada son binarios, porque esta función de perdida compara cada pixel de la imagen de entrada con cada pixel de la imagen reconstruida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35331f59-55eb-4b41-9cc6-45299025153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.6992 - val_loss: 0.6842\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.6761 - val_loss: 0.6629\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6551 - val_loss: 0.6419\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6335 - val_loss: 0.6192\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6096 - val_loss: 0.5937\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5833 - val_loss: 0.5659\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5551 - val_loss: 0.5373\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5270 - val_loss: 0.5097\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5004 - val_loss: 0.4850\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4771 - val_loss: 0.4641\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4575 - val_loss: 0.4472\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4418 - val_loss: 0.4341\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4297 - val_loss: 0.4241\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4205 - val_loss: 0.4162\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4131 - val_loss: 0.4096\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4068 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4013 - val_loss: 0.3986\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3961 - val_loss: 0.3936\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3912 - val_loss: 0.3889\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3865 - val_loss: 0.3844\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3819 - val_loss: 0.3799\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3774 - val_loss: 0.3754\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3727 - val_loss: 0.3708\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3681 - val_loss: 0.3664\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3635 - val_loss: 0.3620\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3591 - val_loss: 0.3576\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3547 - val_loss: 0.3535\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3505 - val_loss: 0.3496\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3466 - val_loss: 0.3459\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3428 - val_loss: 0.3424\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3393 - val_loss: 0.3390\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3359 - val_loss: 0.3359\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3328 - val_loss: 0.3330\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3299 - val_loss: 0.3302\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3272 - val_loss: 0.3277\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3247 - val_loss: 0.3253\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3223 - val_loss: 0.3230\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3201 - val_loss: 0.3210\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3180 - val_loss: 0.3189\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3160 - val_loss: 0.3170\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3142 - val_loss: 0.3152\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3124 - val_loss: 0.3135\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3108 - val_loss: 0.3119\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3092 - val_loss: 0.3104\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3077 - val_loss: 0.3089\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3063 - val_loss: 0.3075\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3049 - val_loss: 0.3062\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3036 - val_loss: 0.3049\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3024 - val_loss: 0.3036\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3012 - val_loss: 0.3025\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3000 - val_loss: 0.3013\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2989 - val_loss: 0.3002\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2978 - val_loss: 0.2991\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2968 - val_loss: 0.2981\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2958 - val_loss: 0.2972\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2948 - val_loss: 0.2961\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2938 - val_loss: 0.2951\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2929 - val_loss: 0.2943\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2920 - val_loss: 0.2934\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2912 - val_loss: 0.2926\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2903 - val_loss: 0.2916\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2895 - val_loss: 0.2908\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2887 - val_loss: 0.2900\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2879 - val_loss: 0.2892\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2871 - val_loss: 0.2884\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2863 - val_loss: 0.2877\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2856 - val_loss: 0.2870\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2849 - val_loss: 0.2863\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2842 - val_loss: 0.2855\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2835 - val_loss: 0.2849\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2828 - val_loss: 0.2842\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2821 - val_loss: 0.2835\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2814 - val_loss: 0.2828\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2808 - val_loss: 0.2822\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2801 - val_loss: 0.2815\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2795 - val_loss: 0.2810\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2788 - val_loss: 0.2803\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2782 - val_loss: 0.2797\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2776 - val_loss: 0.2791\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2770 - val_loss: 0.2785\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2765 - val_loss: 0.2780\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2759 - val_loss: 0.2773\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2753 - val_loss: 0.2768\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2747 - val_loss: 0.2763\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2742 - val_loss: 0.2757\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2737 - val_loss: 0.2752\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2731 - val_loss: 0.2747\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2726 - val_loss: 0.2742\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2721 - val_loss: 0.2737\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2716 - val_loss: 0.2732\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2711 - val_loss: 0.2727\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2706 - val_loss: 0.2722\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2701 - val_loss: 0.2717\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2697 - val_loss: 0.2713\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2692 - val_loss: 0.2708\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2687 - val_loss: 0.2703\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2683 - val_loss: 0.2699\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2678 - val_loss: 0.2695\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2674 - val_loss: 0.2691\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2670 - val_loss: 0.2686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b4ec6cd1d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_entrena, X_entrena, epochs=100, batch_size=256, shuffle=True, validation_data=(X_prueba, X_prueba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa7ffd-cf68-42ff-be55-a22c55207264",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con el mismo conjunto de datos para las entradas como para las salidas esperadas, ya que el objetivo es reconstruir las entradas originales a partir de las representaciones comprimidas, el siguiente argumento que es `epoch` es el número de veces que va a repasar todo el conjunto de datos de entrenamiento, luego sigue `batch_size` o lotes, durante el entrenamiento los datos se dividen en pequeños paquetes o lotes que se procesan de forma independiente, en este caso **batch size** de 256 indica que el modelo debería tomar 256 ejemplos de `X_entrena` a la vez, entrenarlos, actualizar su peso y luego pasar el siguiente lote de 256 ejemplos más, después sigue `shuffle` esto hace que los datos se mezclen antes de cada **epoch**, esto ayuda a prevenir que el modelo aprenda el orden de los datos en lugar de las características subyacentes, y por último `validation_data` es el conjunto de datos para probar que el modelo está aprendiendo correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8518b78f-b955-434b-947a-e7a4af8fed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(X_prueba[i].reshape(8, 8))\n",
    "    plt.subplot(2, 10, i+1+10)\n",
    "    plt.imshow(autoencoder.predict(X_prueba)[i].reshape(8, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
